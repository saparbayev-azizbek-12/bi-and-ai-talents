{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merging and Joining**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Inner Join on Chinook Database**\n",
    "   - Load the `chinook.db` database.\n",
    "   - Perform an inner join between the `customers` and `invoices` tables on the `CustomerId` column.\n",
    "   - Find the total number of invoices for each customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerId  FirstName      LastName  TotalInvoices\n",
      "0            1       Luís     Gonçalves              7\n",
      "1            2     Leonie        Köhler              7\n",
      "2            3   François      Tremblay              7\n",
      "3            4      Bjørn        Hansen              7\n",
      "4            5  František   Wichterlová              7\n",
      "5            6     Helena          Holý              7\n",
      "6            7     Astrid        Gruber              7\n",
      "7            8       Daan       Peeters              7\n",
      "8            9       Kara       Nielsen              7\n",
      "9           10    Eduardo       Martins              7\n",
      "10          11  Alexandre         Rocha              7\n",
      "11          12    Roberto       Almeida              7\n",
      "12          13   Fernanda         Ramos              7\n",
      "13          14       Mark       Philips              7\n",
      "14          15   Jennifer      Peterson              7\n",
      "15          16      Frank        Harris              7\n",
      "16          17       Jack         Smith              7\n",
      "17          18   Michelle        Brooks              7\n",
      "18          19        Tim         Goyer              7\n",
      "19          20        Dan        Miller              7\n",
      "20          21      Kathy         Chase              7\n",
      "21          22    Heather       Leacock              7\n",
      "22          23       John        Gordon              7\n",
      "23          24      Frank       Ralston              7\n",
      "24          25     Victor       Stevens              7\n",
      "25          26    Richard    Cunningham              7\n",
      "26          27    Patrick          Gray              7\n",
      "27          28      Julia       Barnett              7\n",
      "28          29     Robert         Brown              7\n",
      "29          30     Edward       Francis              7\n",
      "30          31     Martha          Silk              7\n",
      "31          32      Aaron      Mitchell              7\n",
      "32          33      Ellie      Sullivan              7\n",
      "33          34       João     Fernandes              7\n",
      "34          35   Madalena       Sampaio              7\n",
      "35          36     Hannah     Schneider              7\n",
      "36          37       Fynn    Zimmermann              7\n",
      "37          38     Niklas      Schröder              7\n",
      "38          39    Camille       Bernard              7\n",
      "39          40  Dominique      Lefebvre              7\n",
      "40          41       Marc        Dubois              7\n",
      "41          42      Wyatt        Girard              7\n",
      "42          43   Isabelle       Mercier              7\n",
      "43          44      Terhi    Hämäläinen              7\n",
      "44          45   Ladislav        Kovács              7\n",
      "45          46       Hugh      O'Reilly              7\n",
      "46          47      Lucas       Mancini              7\n",
      "47          48   Johannes  Van der Berg              7\n",
      "48          49  Stanisław        Wójcik              7\n",
      "49          50    Enrique         Muñoz              7\n",
      "50          51     Joakim     Johansson              7\n",
      "51          52       Emma         Jones              7\n",
      "52          53       Phil        Hughes              7\n",
      "53          54      Steve        Murray              7\n",
      "54          55       Mark        Taylor              7\n",
      "55          56      Diego     Gutiérrez              7\n",
      "56          57       Luis         Rojas              7\n",
      "57          58      Manoj        Pareek              7\n",
      "58          59       Puja    Srivastava              6\n"
     ]
    }
   ],
   "source": [
    "# Load the chinook.db database\n",
    "conn = sqlite3.connect('../data/chinook.db')\n",
    "\n",
    "# Perform an inner join between the customers and invoices tables on the CustomerId column\n",
    "query = '''\n",
    "SELECT customers.CustomerId, customers.FirstName, customers.LastName, COUNT(invoices.InvoiceId) as TotalInvoices\n",
    "FROM customers\n",
    "INNER JOIN invoices ON customers.CustomerId = invoices.CustomerId\n",
    "GROUP BY customers.CustomerId\n",
    "'''\n",
    "\n",
    "# Execute the query and load the data into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Outer Join on Movie Data**\n",
    "   - Load the `movie.csv` file.\n",
    "   - Create two smaller DataFrames:\n",
    "     - One with only `director_name` and `color`.\n",
    "     - Another with `director_name` and `num_critic_for_reviews`.\n",
    "   - Perform a left join and then a full outer join on `director_name`.\n",
    "   - Count how many rows are in the resulting DataFrames for each join type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in left join DataFrame: 30300\n",
      "Number of rows in full outer join DataFrame: 30300\n"
     ]
    }
   ],
   "source": [
    "# Load the movie.csv file\n",
    "movie_df = pd.read_csv('../data/movie.csv')\n",
    "\n",
    "# Create two smaller DataFrames\n",
    "df1 = movie_df[['director_name', 'color']]\n",
    "df2 = movie_df[['director_name', 'num_critic_for_reviews']]\n",
    "\n",
    "# Perform a left join on director_name\n",
    "left_join_df = pd.merge(df1, df2, on='director_name', how='left')\n",
    "\n",
    "# Perform a full outer join on director_name\n",
    "outer_join_df = pd.merge(df1, df2, on='director_name', how='outer')\n",
    "\n",
    "# Count the number of rows in the resulting DataFrames for each join type\n",
    "left_join_count = left_join_df.shape[0]\n",
    "outer_join_count = outer_join_df.shape[0]\n",
    "\n",
    "print(f'Number of rows in left join DataFrame: {left_join_count}')\n",
    "print(f'Number of rows in full outer join DataFrame: {outer_join_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Grouping and Aggregating**\n",
    "1. **Grouped Aggregations on Titanic**\n",
    "   - Group passengers by `Pclass` and calculate the following:\n",
    "     - Average age.\n",
    "     - Total fare.\n",
    "     - Count of passengers.\n",
    "   - Save the results to a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Average Age  Total Fare  Passenger Count\n",
      "Pclass                                          \n",
      "1         38.233441  18177.4125              216\n",
      "2         29.877630   3801.8417              184\n",
      "3         25.140620   6714.6951              491\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_excel('../data/titanic.xlsx')\n",
    "\n",
    "# Group passengers by Pclass and calculate the average age, total fare, and count of passengers\n",
    "grouped_df = titanic_df.groupby('Pclass').agg({\n",
    "    'Age': 'mean',\n",
    "    'Fare': 'sum',\n",
    "    'PassengerId': 'count'\n",
    "}).rename(columns={'Age': 'Average Age', 'Fare': 'Total Fare', 'PassengerId': 'Passenger Count'})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Multi-level Grouping on Movie Data**\n",
    "   - Group the movies by `color` and `director_name`.\n",
    "   - Find:\n",
    "     - Total `num_critic_for_reviews` for each group.\n",
    "     - Average `duration` for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Total Critic Reviews  Average Duration\n",
      "color           director_name                                             \n",
      "Black and White Akira Kurosawa                     153.0             202.0\n",
      "                Aleksey German                     121.0             177.0\n",
      "                Alex Garland                       489.0             108.0\n",
      "                Alexander Payne                    433.0             115.0\n",
      "                Alfred Hitchcock                   434.0             119.0\n",
      "...                                                  ...               ...\n",
      "Color           Zoran Lisinac                       17.0             108.0\n",
      "                Álex de la Iglesia                  71.0             104.0\n",
      "                Émile Gaudreault                    67.0              92.0\n",
      "                Éric Tessier                         9.0              99.0\n",
      "                Étienne Faure                        9.0              98.0\n",
      "\n",
      "[2490 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group the movies by color and director_name\n",
    "grouped_movie_df = movie_df.groupby(['color', 'director_name']).agg({\n",
    "    'num_critic_for_reviews': 'sum',\n",
    "    'duration': 'mean'\n",
    "}).rename(columns={'num_critic_for_reviews': 'Total Critic Reviews', 'duration': 'Average Duration'})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(grouped_movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Nested Grouping on Flights**\n",
    "   - Group flights by `Year` and `Month` and calculate:\n",
    "     - Total number of flights.\n",
    "     - Average arrival delay (`ArrDelay`).\n",
    "     - Maximum departure delay (`DepDelay`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Total Flights  Average Arrival Delay\n",
      "model               mpg                                       \n",
      "AMC Javelin         15.2              1                   15.2\n",
      "Cadillac Fleetwood  10.4              1                   10.4\n",
      "Camaro Z28          13.3              1                   13.3\n",
      "Chrysler Imperial   14.7              1                   14.7\n",
      "Datsun 710          22.8              1                   22.8\n",
      "Dodge Challenger    15.5              1                   15.5\n",
      "Duster 360          14.3              1                   14.3\n",
      "Ferrari Dino        19.7              1                   19.7\n",
      "Fiat 128            32.4              1                   32.4\n",
      "Fiat X1-9           27.3              1                   27.3\n",
      "Ford Pantera L      15.8              1                   15.8\n",
      "Honda Civic         30.4              1                   30.4\n",
      "Hornet 4 Drive      21.4              1                   21.4\n",
      "Hornet Sportabout   18.7              1                   18.7\n",
      "Lincoln Continental 10.4              1                   10.4\n",
      "Lotus Europa        30.4              1                   30.4\n",
      "Maserati Bora       15.0              1                   15.0\n",
      "Mazda RX4           21.0              1                   21.0\n",
      "Mazda RX4 Wag       21.0              1                   21.0\n",
      "Merc 230            22.8              1                   22.8\n",
      "Merc 240D           24.4              1                   24.4\n",
      "Merc 280            19.2              1                   19.2\n",
      "Merc 280C           17.8              1                   17.8\n",
      "Merc 450SE          16.4              1                   16.4\n",
      "Merc 450SL          17.3              1                   17.3\n",
      "Merc 450SLC         15.2              1                   15.2\n",
      "Pontiac Firebird    19.2              1                   19.2\n",
      "Porsche 914-2       26.0              1                   26.0\n",
      "Toyota Corolla      33.9              1                   33.9\n",
      "Toyota Corona       21.5              1                   21.5\n",
      "Valiant             18.1              1                   18.1\n",
      "Volvo 142E          21.4              1                   21.4\n"
     ]
    }
   ],
   "source": [
    "# Load the flights dataset\n",
    "flights_df = pd.read_parquet('../data/mtcars.parquet')\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = {'model', 'mpg', 'cyl', 'disp'}\n",
    "missing_columns = required_columns - set(flights_df.columns)\n",
    "\n",
    "grouped_flights_df = flights_df.groupby(['model', 'mpg']).agg({\n",
    "    'model': 'count',\n",
    "    'mpg': 'mean',\n",
    "}).rename(columns={'model': 'Total Flights', 'mpg': 'Average Arrival Delay'})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(grouped_flights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Applying Functions**\n",
    "1. **Apply a Custom Function on Titanic**\n",
    "   - Write a function to classify passengers as `Child` (age < 18) or `Adult`.\n",
    "   - Use `apply` to create a new column, `Age_Group`, with these values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age Age_Group\n",
      "0    22.0     Adult\n",
      "1    38.0     Adult\n",
      "2    26.0     Adult\n",
      "3    35.0     Adult\n",
      "4    35.0     Adult\n",
      "..    ...       ...\n",
      "886  27.0     Adult\n",
      "887  19.0     Adult\n",
      "888   NaN     Adult\n",
      "889  26.0     Adult\n",
      "890  32.0     Adult\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the custom function to classify passengers\n",
    "def classify_age(age):\n",
    "    if age < 18:\n",
    "        return 'Child'\n",
    "    else:\n",
    "        return 'Adult'\n",
    "\n",
    "# Apply the function to create a new column 'Age_Group'\n",
    "titanic_df['Age_Group'] = titanic_df['Age'].apply(classify_age)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(titanic_df[['Age', 'Age_Group']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Normalize Employee Salaries**\n",
    "   - Load the `employee.csv` file.\n",
    "   - Normalize the salaries within each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         DEPARTMENT  BASE_SALARY  NORMALIZED_SALARY\n",
      "0       Municipal Courts Department     121862.0           2.568478\n",
      "1                           Library      26125.0          -0.962884\n",
      "2     Houston Police Department-HPD      45279.0          -0.892524\n",
      "3     Houston Fire Department (HFD)      63166.0           0.214332\n",
      "4       General Services Department      56347.0           0.224533\n",
      "...                             ...          ...                ...\n",
      "1995  Houston Police Department-HPD      43443.0          -1.001846\n",
      "1996  Houston Fire Department (HFD)      66523.0           0.412156\n",
      "1997  Houston Police Department-HPD      43443.0          -1.001846\n",
      "1998  Houston Police Department-HPD      55461.0          -0.286254\n",
      "1999  Houston Fire Department (HFD)      51194.0          -0.491163\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the employee.csv file\n",
    "employee_df = pd.read_csv('../data/emplayee.csv')\n",
    "\n",
    "# Define a function to normalize the salaries\n",
    "def normalize_salary(salary, department):\n",
    "    dept_salaries = employee_df[employee_df['DEPARTMENT'] == department]['BASE_SALARY']\n",
    "    return (salary - dept_salaries.mean()) / dept_salaries.std()\n",
    "\n",
    "# Apply the function to normalize the salaries within each department\n",
    "employee_df['NORMALIZED_SALARY'] = employee_df.apply(lambda row: normalize_salary(row['BASE_SALARY'], row['DEPARTMENT']), axis=1)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(employee_df[['DEPARTMENT', 'BASE_SALARY', 'NORMALIZED_SALARY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Custom Function on Movies**\n",
    "   - Write a function that returns `Short`, `Medium`, or `Long` based on the duration of a movie:\n",
    "     - `Short`: Less than 60 minutes.\n",
    "     - `Medium`: Between 60 and 120 minutes.\n",
    "     - `Long`: More than 120 minutes.\n",
    "   - Apply this function to classify movies in the `movie.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      duration Duration_Category\n",
      "0        178.0              Long\n",
      "1        169.0              Long\n",
      "2        148.0              Long\n",
      "3        164.0              Long\n",
      "4          NaN              Long\n",
      "...        ...               ...\n",
      "4911      87.0            Medium\n",
      "4912      43.0             Short\n",
      "4913      76.0            Medium\n",
      "4914     100.0            Medium\n",
      "4915      90.0            Medium\n",
      "\n",
      "[4916 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the custom function to classify movies based on duration\n",
    "def classify_duration(duration):\n",
    "    if duration < 60:\n",
    "        return 'Short'\n",
    "    elif 60 <= duration <= 120:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Long'\n",
    "\n",
    "# Apply the function to create a new column 'Duration_Category'\n",
    "movie_df['Duration_Category'] = movie_df['duration'].apply(classify_duration)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(movie_df[['duration', 'Duration_Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Using `pipe`**\n",
    "1. **Pipeline on Titanic**\n",
    "   - Create a pipeline to:\n",
    "     - Filter passengers who survived (`Survived == 1`).\n",
    "     - Fill missing `Age` values with the mean.\n",
    "     - Create a new column, `Fare_Per_Age`, by dividing `Fare` by `Age`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived   Age     Fare  Fare_Per_Age\n",
      "1           1  38.0  71.2833      1.875876\n",
      "2           1  26.0   7.9250      0.304808\n",
      "3           1  35.0  53.1000      1.517143\n",
      "8           1  27.0  11.1333      0.412344\n",
      "9           1  14.0  30.0708      2.147914\n",
      "..        ...   ...      ...           ...\n",
      "875         1  15.0   7.2250      0.481667\n",
      "879         1  56.0  83.1583      1.484970\n",
      "880         1  25.0  26.0000      1.040000\n",
      "887         1  19.0  30.0000      1.578947\n",
      "889         1  26.0  30.0000      1.153846\n",
      "\n",
      "[342 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_17936\\1152674106.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_17936\\1152674106.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_17936\\1152674106.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Fare_Per_Age'] = df['Fare'] / df['Age']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to filter passengers who survived\n",
    "def filter_survived(df):\n",
    "    return df[df['Survived'] == 1]\n",
    "\n",
    "# Define a function to fill missing Age values with the mean\n",
    "def fill_missing_age(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    return df\n",
    "\n",
    "# Define a function to create a new column Fare_Per_Age\n",
    "def create_fare_per_age(df):\n",
    "    df['Fare_Per_Age'] = df['Fare'] / df['Age']\n",
    "    return df\n",
    "\n",
    "# Create the pipeline\n",
    "titanic_pipeline_df = (titanic_df\n",
    "                       .pipe(filter_survived)\n",
    "                       .pipe(fill_missing_age)\n",
    "                       .pipe(create_fare_per_age))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(titanic_pipeline_df[['Survived', 'Age', 'Fare', 'Fare_Per_Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Pipeline on Flights**\n",
    "   - Create a pipeline to:\n",
    "     - Filter flights with a departure delay greater than 30 minutes.\n",
    "     - Add a column `Delay_Per_Hour` by dividing the delay by the scheduled flight duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model   mpg  cyl  ratio\n",
      "17        Fiat 128  32.4    4  8.100\n",
      "18     Honda Civic  30.4    4  7.600\n",
      "19  Toyota Corolla  33.9    4  8.475\n",
      "27    Lotus Europa  30.4    4  7.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_17936\\3032237569.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ratio'] = df['mpg'] / df['cyl']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to filter flights with a departure delay greater than 30 minutes\n",
    "def filter_departure_delay(df):\n",
    "    return df[df['mpg'] > 30]\n",
    "\n",
    "# Define a function to add a column Delay_Per_Hour by dividing the delay by the scheduled flight duration\n",
    "def add_delay_per_hour(df):\n",
    "    df['ratio'] = df['mpg'] / df['cyl']\n",
    "    return df\n",
    "\n",
    "# Create the pipeline\n",
    "flights_pipeline_df = (flights_df\n",
    "                       .pipe(filter_departure_delay)\n",
    "                       .pipe(add_delay_per_hour))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(flights_pipeline_df[['model', 'mpg', 'cyl', 'ratio']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
